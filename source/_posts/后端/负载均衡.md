---
title: 负载均衡
tags: [负载均衡]      #添加的标签
categories: 
  - 后端
description: 
#cover: 
---



## 概念

负载均衡，英文名称为Load Balance，其含义就是指将负载（工作任务或者网络请求）进行平衡，分摊到多个操作单元(服务器或者组件)上进行运行。目的是尽量将网络流量 ***平均*** 发送到多个服务器上，以保证整个业务系统的高可用。

![负载均衡1](https://raw.githubusercontent.com/OverCookkk/PicBed/master/blogImg/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A11.jpg)

如何构建和调度服务集群这事情，又必须对用户一侧保持足够的透明，即使请求背后是由一千台、一万台机器来共同响应的，也绝非用户所关心的事情，用户需记住的只有一个域名地址而已。调度后方的多台机器，以统一的接口对外提供服务，承担此职责的技术组件被称为 ***负载均衡***。

负载均衡主要有以下作用：

- 高并发。通过采取一定的算法策略，将流量尽可能的均匀发送给后端的实例，以此提高集群的并发处理能力。
- 伸缩性。根据网络流量的大小，增加或者减少后端服务器实例，由负载均衡设备进行控制，这样使得集群具有伸缩性。
- 高可用。负载均衡器通过算法或者其他性能数据来监控候选实例，当实例负载过高或者异常时，减少其流量请求或者直接跳过该实例，将请求发送个其他可用实例，这使得集群具有高可用的特性。
- 安全防护。有些负载均衡器提供了安全防护功能。如：黑白名单处理、防火墙等。



## 分类

### 根据载体类型分类

从支持负载均衡的载体来看，可以将负载均衡分为两类：

- 硬件负载均衡
- 软件负载均衡

#### 硬件负载均衡

硬件负载平衡器是一种硬件设备，具有专门的操作系统。硬件负载平衡器位于传入流量和内部服务器之间，本质上充当“流量警察”。当用户访问网站或者使用app某个功能时，它们首先被发送到负载均衡器，然后负载均衡器根据一定的策略，将流量转发到后端不同的服务器。为确保最佳性能，硬件负载均衡器根据自定义规则分配流量，以免后端实例不堪重负。

传统上，硬件负载平衡器和应用服务器部署在本地数据中心，负载平衡器的数量取决于预期的峰值流量。负载均衡器通常成对部署，以防其中一个失败。

目前业界领先的两款硬件负载均衡器：F5和A10

![硬件负载均衡](https://raw.githubusercontent.com/OverCookkk/PicBed/master/blogImg/%E7%A1%AC%E4%BB%B6%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1.jpg)



**优点**：

> 功能强大：支持全局负载均衡并提供较全面的、复杂的负载均衡算法。
>
> 性能强悍：硬件负载均衡由于是在专用处理器上运行，因此吞吐量大，可支持单机百万以上的并发。
>
> 安全性高：往往具备防火墙，防 DDos 攻击等安全功能。

**缺点**

> 成本昂贵：购买和维护硬件负载均衡的成本都很高(：F5价格在15w~55w不等，A10价格在55w-100w不等)。
>
> 扩展性差：当访问量突增时，超过限度不能动态扩容。





#### 软件负载均衡

软件负载均衡指的是在服务器的操作系统上安装负载均衡软件，从此服务器发出的请求经软件负载均衡算法路由到后端集群的某一台机器上。

常见负载均衡软件有：LVS、Nginx、Haproxy。

**优点**

> 扩展性好：适应动态变化，可以通过添加软件负载均衡实例，动态扩展到超出初始容量的能力。
>
> 成本低廉：软件负载均衡可以在任何标准物理设备上运行，降低了购买和运维的成本。

**缺点**

> 性能略差：相比于硬件负载均衡，软件负载均衡的性能要略低一些。



### 根据OSI网络模型分类

![OSI模型](https://raw.githubusercontent.com/OverCookkk/PicBed/master/blogImg/OSI%E6%A8%A1%E5%9E%8B.jpg)

从上图可以看出：

> TELNET、HTTP、FTP、NFS、SMTP、DNS等属于第七层应用层的概念。
>
> TCP、UDP、SPX等属于第四层传输层的概念。
>
> IP、IPX等属于第三层网络层的概念。
>
> ATM、FDDI等属于第二层数据链路层的概念。

根据负载均衡技术实现在OSI七层模型的不同层次，我们给负载均衡分类：

- 七层负载均衡：工作在应用层的负载均衡称
- 四层负载均衡：工作在传输层的负载均衡称
- 三层负载均衡：工作在网络层的负载均衡，
- 二层负载均衡：工作在数据链路层的负载均衡。

![负载均衡OSI](https://raw.githubusercontent.com/OverCookkk/PicBed/master/blogImg/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1OSI.jpg)

***其中最常用的是四层和七层负载均衡***。

#### 四层负载均衡

> 所谓四层负载均衡，也就是主要通过报文中的目标地址和端口，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。

由于四层负载均衡是作用在传输层，因此，我们就以常见的TCP进行举例。

负载均衡设备在接收到第一个来自客户端的SYN 请求时，即通过上述方式选择一个最佳的服务器，并对报文中目标IP地址进行修改(改为后端服务器IP），直接转发给该服务器。TCP的连接建立，即三次握手是客户端和服务器直接建立的，负载均衡设备只是起到一个类似路由器的转发动作。在某些部署情况下，为保证服务器回包可以正确返回给负载均衡设备，在转发报文的同时可能还会对报文原来的源地址进行修改。

![四层负载均衡](https://raw.githubusercontent.com/OverCookkk/PicBed/master/blogImg/%E5%9B%9B%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1.jpg)

四层负载均衡主要是基于tcp协议报文，可以做任何基于tcp/ip协议的软件的负载均衡，比如Haproxy、LVS等。



#### 七层负载均衡

> 所谓七层负载均衡，也称为“内容交换”，也就是主要通过报文中的真正有意义的应用层内容，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。

应用层协议较多，常用http、radius、dns等。七层负载就可以基于这些协议来负载。

我们仍然以TCP为例。负载均衡设备如果要根据真正的应用层内容再选择服务器，只能先代理最终的服务器和客户端建立连接(三次握手)后，才可能接受到客户端发送的真正应用层内容的报文，然后再根据该报文中的特定字段，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。负载均衡设备在这种情况下，更类似于一个代理服务器。负载均衡和前端的客户端以及后端的服务器会分别建立TCP连接。所以从这个技术原理上来看，七层负载均衡明显的对负载均衡设备的要求更高，处理七层的能力也必然会低于四层模式的部署方式。

> 七层负载均衡器会与客户端 以及 后端的服务实例分别建立连接

![七层负载均衡](https://raw.githubusercontent.com/OverCookkk/PicBed/master/blogImg/%E4%B8%83%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1.jpg)



#### 对比(四层和七层)

- 智能性

- - 七层负载均衡由于具备OIS七层的所有功能，所以在处理用户需求上能更加灵活，从理论上讲，七层模型能对用户的所有跟服务端的请求进行修改。例如对文件header添加信息，根据不同的文件类型进行分类转发。
  - 四层模型仅支持基于网络层的需求转发，不能修改用户请求的内容。

- 安全性

- - 七层负载均衡由于具有OSI模型的全部功能，能更容易抵御来自网络的攻击
  - 四层模型从原理上讲，会直接将用户的请求转发给后端节点，无法直接抵御网络攻击。

- 复杂度

- - 四层模型一般比较简单的架构，容易管理，容易定位问题
  - 七层模型架构比较复杂，通常也需要考虑结合四层模型的混用情况，出现问题定位比较复杂。

- 效率比

- - 四层模型基于更底层的设置，通常效率更高，但应用范围有限
  - 七层模型需要更多的资源损耗，在理论上讲比四层模型有更强的功能，现在的实现更多是基于http应用。
