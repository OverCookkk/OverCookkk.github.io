数据集通常可以分成两部分：训练数据集用于拟合模型参数，测试数据集用于评估拟合的模型。

过拟合（overfitting）：当一个模型在训练集上表现良好，但在测试集时测试时候表现并不好。





词义理解

1、**词向量的维度**（通常为512）

2、卷积（convolution：本质不变的变换）：**卷积的本质是滤波（特征提取），操作是加权平均、乘加运算，其目的是提取有用信息。**

> 延伸阅读：在通常的深度学习卷积层，有填充（Padding）、步长（Stride）的概念，这样做的好处是对防止图像边缘信息丢失、图像尺寸的控制更好，这使得操作与二维卷积的经典公式差别更大，但是convolution的本质含义并没有改变。



信号处理领域：卷积就是对信号进行滤波

图像领域：卷积就是对图像特征的提取



3、梯度

梯度是一个矢量，在其方向上的方向导数最大，也就是函数在该点处沿着梯度的方向变化最快，变化率最大。

那么在机器学习中逐步逼近、迭代求解最优化时，经常会使用到梯度，沿着梯度向量的方向是函数增加的最快，更容易找到函数的最大值，反过来，沿着梯度向量相反的地方，梯度减少的最快，更容易找到最小值。



PyTorch的自动微分引擎只能计算标量输出的梯度。换句话说，如果你试图在一个非标量值（如一个张量）上调用`.backward()`，就会出现这个错误。这是因为梯度是一个向量，不能自动计算一个向量对一个向量的导数，需要将一个向量转换为一个标量值，比如将一个向量的所有元素相加，得到一个标量，然后再计算其梯度。因此，如果你想对一个张量求导，你需要将它的所有元素进行加权平均，得到一个标量输出，然后再计算它的梯度。

∂loss/∂b 和 ∂loss/∂w 就是损失函数关于偏置 b 和权重 w 的梯度，通常简称为梯度。梯度是一个向量，它的每个元素对应一个参数，表示在该参数上增加一个微小的变化会对损失函数产生多大的影响。



反向传播：

在反向传播过程中，我们需要计算损失函数对每个参数的梯度，这需要从损失函数出发，将梯度信息沿着网络层反向传递。具体来说，我们首先计算输出的损失函数关于输出层的输出的梯度，然后将梯度沿着网络层反向传递，一直到输入层。在反向传播的过程中，每个神经元会接收来自上一层神经元的梯度，然后根据链式法则计算本层神经元的梯度，并将梯度传递给下一层。



计算图：

计算图（Computation Graph）是机器学习中一种重要的概念，用于描述计算过程中各个变量之间的依赖关系。

在计算图中，每个节点表示一个变量或操作，每条边表示变量之间的依赖关系。计算图中的计算过程通常分为两个阶段：前向传播和反向传播。在前向传播阶段，从输入节点开始，按照依赖关系依次计算每个节点的值，最终得到输出节点的值；在反向传播阶段，从输出节点开始，按照依赖关系依次计算每个节点的梯度，最终得到输入节点的梯度。这种按照依赖关系计算的过程称为自动微分（Automatic Differentiation），也称为反向传播算法（Backpropagation）。

PyTorch 中的张量（Tensor）和模型（Module）都可以构建计算图，每个张量和模型都是计算图中的一个节点。在进行前向传播和反向传播时，PyTorch 会自动构建计算图，并根据计算图计算每个节点的值和梯度。

计算图是机器学习中重要的概念之一，它可以帮助我们更好地理解模型的计算过程和梯度的计算过程，从而更好地设计和优化机器学习模型。





导数是微积分学中重要的基础概念，**简单来讲就是指一个函数在某一点处的变化率。**

- **导数 表示 变化率**
- **微分 表示 变化量**

**偏导数指的是多元函数在某一点处关于某一变量的导数。**

**梯度其实就是一个包含所有偏导数的向量**，表示某一函数在该点处的方向导数沿着该方向取得最大值，即函数在该点处沿着该方向变化最快，变化率最大。





激活函数是非线性的，它的本质是引入非线性



交叉熵



图像的项目跟embedding有什么关系，为什么不需要转换成embedding进行处理

embedding是张量吗



什么是解决非线性问题：例如图像分类、自然语言处理等。

线性问题



损失函数（loss function），或“目标函数”、“代价函数”

如果使用的是回归问题的均方误差（MSE）作为目标函数，就可以根据均方误差的大小来调整模型的参数。

怎么定义目标函数，代码怎么对应





上采样是指将特征图的分辨率还原到原始图片的分辨率大小





安装anaconda更改镜像源

```text
pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple
```







向量还可以被用来表示向量空间模型的线性变换。在机器学习中，可以通过矩阵乘法来对向量进行线性变换。这种变换可以用来调整向量的方向和大小，从而使模型能够更好地学习数据。







```
self.block8 = nn.Sequential(*block8) #星号代表什么
```

```
netG.train()  # 开启训练模式，为什么线性模型不需要训练模式
```

torchvision.transforms.Compose：*这个类的主要作用是串联多个图片变换的操作。*





```python
import torch

# 创建一个 2x3x4 的张量
A = torch.tensor([[[83, 76, 89, 91], [78, 84, 79, 85], [89, 92, 87, 94]],
                  [[91, 87, 92, 89], [85, 88, 87, 90], [90, 93, 91, 94]]])

# 获取第二个学生的数学成绩的所有考试成绩
math_scores = A[1][0][:]  # tensor([85, 88, 87, 90])

# 获取所有学生在第二次考试中的所有成绩
second_exam_scores = A[:, 1, 1]  # tensor([84, 88])
```

这个 2x3x4 的张量中的每个数字分别代表着学生成绩的不同信息：

- 第一个维度（axis 0）表示学生的序号，包含两个学生。
- 第二个维度（axis 1）表示科目，包含三个科目：数学、英语和体育。
- 第三个维度（axis 2）表示考试次数，每个学科包含四次考试成绩。

这里，我们使用 PyTorch 的函数 `torch.tensor()` 来创建了一个 2x3x4 的张量 A，它保存了学生的成绩信息。然后，我们通过索引来获取了该张量中的数据。

`A[1][0][:]` 表示获取第二个学生的数学成绩的所有考试成绩，我们在第一个维度上使用了索引 1，表示获取第二个学生的信息；在第二个维度上使用了索引 0，表示获取数学这一科目的信息；在第三个维度上使用了`:`，表示获取该学生在所有数学考试中的成绩。最终返回了一个包含四个元素的一维张量（tensor）。

`A[:, 1, 1]` 表示获取所有学生在第二次考试中的所有成绩，我们在第一个维度上使用了`:`，表示获取所有学生的信息；在第二个维度上使用了索引 1，表示获取英语这一科目的信息；在第三个维度上使用了索引 1，表示获取所有学生在第二次考试中的成绩。最终返回了一个包含两个元素的一维张量。